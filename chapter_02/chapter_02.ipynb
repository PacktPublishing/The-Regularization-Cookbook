{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51cfabc",
   "metadata": {},
   "source": [
    "# Machine Learning refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4625d",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d129e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ff65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as a DataFrame\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f22c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7f615",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7371b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['Survived']), df['Survived'], test_size=0.2, stratify=df['Survived'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75465975",
   "metadata": {},
   "source": [
    "## Preparing quantitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de75afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78feaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quanti_columns = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n",
    "# Get the quantitative columns\n",
    "X_train_quanti = X_train[quanti_columns]\n",
    "X_test_quanti = X_test[quanti_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f7c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing quantitative values with mean feature value\n",
    "quanti_imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bc9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and impute the training set\n",
    "X_train_quanti = quanti_imputer.fit_transform(X_train_quanti)\n",
    "# Just impute the test set\n",
    "X_test_quanti = quanti_imputer.transform(X_test_quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8380c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the standard scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91f3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training set\n",
    "X_train_quanti = scaler.fit_transform(X_train_quanti)\n",
    "# Just transform the test set\n",
    "X_test_quanti = scaler.transform(X_test_quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd0faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Age       146\n",
       "Fare        0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Display the number of missing data for each column\n",
    "X_train[quanti_columns].isna().sum()#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1583a0",
   "metadata": {},
   "source": [
    "## Preparing qualitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136b5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff971c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_columns = ['Sex', 'Embarked']\n",
    "# Get the quantitative columns\n",
    "X_train_quali = X_train[quali_columns]\n",
    "X_test_quali = X_test[quali_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52990cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing qualitative values with most frequent feature value\n",
    "quali_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2516e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and impute the training set\n",
    "X_train_quali = quali_imputer.fit_transform(X_train_quali)\n",
    "# Just impute the test set\n",
    "X_test_quali = quali_imputer.transform(X_test_quali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9cae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoder\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1054ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training set\n",
    "X_train_quali = encoder.fit_transform(X_train_quali).toarray()\n",
    "# Just encode the test set\n",
    "X_test_quali = encoder.transform(X_test_quali).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34792825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data back together\n",
    "X_train = np.concatenate([X_train_quanti, X_train_quali], axis=1)\n",
    "X_test = np.concatenate([X_test_quanti, X_test_quali], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee54f1",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff942e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump((X_train, X_test, y_train, y_test), open('prepared_titanic.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf5ec6",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7833b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "242e0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2f5421d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on the training data\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40baa8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store predictions on the test data\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa8419",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23cef7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set: 0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Compute the accuracy on test of our model\n",
    "print('accuracy on test set:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54861",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7e11da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1e82541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters we want to test\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.03, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c50b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search object\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5ba6e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.03, 0.1]}, return_train_score=True,\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and wait\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "743a8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ba0c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimized accuracy: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "print('Hyperparameter optimized accuracy:', accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
